import os
import json
from textwrap import dedent
import streamlit as st
from datetime import datetime
from agno.agent import Agent
from agno.models.openai.like import OpenAILike
from agno.tools import tool
from agno.tools.reasoning import ReasoningTools
from typing import Any, Callable, Dict
from sqlalchemy import create_engine, text
from sqlalchemy.engine import Engine
from decimal import Decimal
from agno.tools.tavily import TavilyTools

st.set_page_config(layout="wide")

# è‡ªå®šä¹‰å·¥å…·é’©å­
def logger_hook(function_name: str, function_call: Callable, arguments: Dict[str, Any]):
    """Hook function that wraps the tool execution"""
    print(f"About to call {function_name} with arguments: {arguments}")
    result = function_call(**arguments)
    print(f"Function call completed with result: {result}")
    return result

# å®šä¹‰KPIè¯†åˆ«å·¥å…·
@tool(
    name="identify_kpi",
    description="è¯†åˆ«ç”¨æˆ·æƒ³è¦æŸ¥è¯¢çš„KPIç±»å‹",
    show_result=True,
    tool_hooks=[logger_hook]
)
def identify_kpi(user_question: str) -> str:
    """æ ¹æ®ç”¨æˆ·é—®é¢˜è¯†åˆ«KPIç±»å‹"""
    # å…ˆåŠ è½½æ‰€æœ‰KPIä¿¡æ¯
    kpi_info_list = []
    kpi_directory = "/home/Finance_v2/kpi_matrix/kpis"
    
    # è¯»å–æ‰€æœ‰KPIæ–‡ä»¶
    for i in range(1, 11):
        kpi_file_path = os.path.join(kpi_directory, f"{i}.json")
        if os.path.exists(kpi_file_path):
            with open(kpi_file_path, 'r', encoding='utf-8') as f:
                kpi_data = json.load(f)
                kpi_info = {
                    "id": str(i),
                    "name": kpi_data["kpi_desc"]["name"],
                    "description": kpi_data["kpi_desc"]["description"],
                    "measures": kpi_data["measures"],
                    "dimensions": kpi_data["dimensions"]
                }
                kpi_info_list.append(kpi_info)
    
    # åˆ›å»ºå…³é”®è¯æ˜ å°„ï¼ŒåŸºäºå®é™…çš„KPIä¿¡æ¯
    kpi_keywords = {}
    for kpi in kpi_info_list:
        keywords = []
        # ä»KPIåç§°å’Œæè¿°ä¸­æå–å…³é”®è¯
        name_keywords = kpi["name"].lower().split()
        desc_keywords = kpi["description"].lower().split()
        
        # æ·»åŠ ç»´åº¦å’Œåº¦é‡å…³é”®è¯
        dim_keywords = [dim.lower() for dim in kpi["dimensions"]]
        measure_keywords = [measure.lower() for measure in kpi["measures"]]
        
        # åˆå¹¶æ‰€æœ‰å…³é”®è¯
        all_keywords = name_keywords + desc_keywords + dim_keywords + measure_keywords
        
        # æ¸…ç†å…³é”®è¯ï¼Œç§»é™¤å¸¸è§åœç”¨è¯å’Œç‰¹æ®Šå­—ç¬¦
        cleaned_keywords = []
        for keyword in all_keywords:
            # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
            cleaned_keyword = ''.join(e for e in keyword if e.isalnum())
            if len(cleaned_keyword) > 1:  # åªä¿ç•™é•¿åº¦å¤§äº1çš„è¯
                cleaned_keywords.append(cleaned_keyword)
        
        kpi_keywords[kpi["id"]] = list(set(cleaned_keywords))  # å»é‡
    
    # åŒ¹é…ç”¨æˆ·é—®é¢˜ä¸KPIå…³é”®è¯
    user_question_lower = user_question.lower()
    
    # ä¸ºæ¯ä¸ªKPIè®¡ç®—åŒ¹é…åˆ†æ•°
    kpi_scores = {}
    for kpi_id, keywords in kpi_keywords.items():
        score = 0
        for keyword in keywords:
            if keyword in user_question_lower:
                score += 1
        kpi_scores[kpi_id] = score
    
    # æ‰¾åˆ°æœ€é«˜åˆ†çš„KPI
    if kpi_scores:
        best_kpi = max(kpi_scores, key=kpi_scores.get)
        # åªæœ‰å½“åŒ¹é…åˆ†æ•°å¤§äº0æ—¶æ‰è¿”å›è¯¥KPI
        if kpi_scores[best_kpi] > 0:
            return best_kpi
    
    return "0"  # 0è¡¨ç¤ºæœªè¯†åˆ«å‡ºç‰¹å®šKPIï¼Œé—²èŠ

# å®šä¹‰è·å–KPIä¿¡æ¯å·¥å…·
@tool(
    name="get_kpi_info",
    description="è·å–KPIçš„è¯¦ç»†ä¿¡æ¯",
    show_result=True,
    tool_hooks=[logger_hook]
)
def get_kpi_info(kpi_id: str) -> dict:
    """è·å–æŒ‡å®šKPIçš„è¯¦ç»†ä¿¡æ¯"""
    kpi_file_path = f"/home/Finance_v2/kpi_matrix/kpis/{kpi_id}.json"
    
    if not os.path.exists(kpi_file_path):
        return {"error": "KPI not found"}
    
    with open(kpi_file_path, 'r', encoding='utf-8') as f:
        kpi_data = json.load(f)
    
    return kpi_data

# å®šä¹‰MySQLæŸ¥è¯¢å·¥å…·
@tool(
    name="query_mysql",
    description="æ‰§è¡ŒMySQLæŸ¥è¯¢",
    show_result=True,
    tool_hooks=[logger_hook]
)
def query_mysql(sql_query: str) -> str:
    """ä½¿ç”¨SQLAlchemyæ‰§è¡ŒMySQLæŸ¥è¯¢å¹¶è¿”å›ç»“æœ"""
    # æ•°æ®åº“è¿æ¥å‚æ•°
    # è¿™äº›å‚æ•°åº”è¯¥ä»é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ä¸­è·å–
    db_params = {
        "host": "localhost",
        "port": 3306,
        "username": "finance",
        "password": "ieWdNpW487t5xcTY",
        "database": "finance"
    }
    
    # åˆ›å»ºæ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²
    db_uri = f"mysql+pymysql://{db_params['username']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['database']}"
    
    try:
        # åˆ›å»ºSQLAlchemyå¼•æ“
        engine: Engine = create_engine(db_uri, pool_pre_ping=True, pool_recycle=1800,
                                       connect_args={"connect_timeout": 5, "read_timeout": 30, "write_timeout": 30},
                                       echo=False, future=True)
        
        # æ‰§è¡ŒæŸ¥è¯¢
        with engine.connect() as conn:
            result = conn.execute(text(sql_query))
            rows = result.fetchall()
            columns = result.keys()
            
            # å°†ç»“æœè½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨ï¼Œå¹¶å¤„ç† Decimal ç±»å‹
            def default_serializer(obj):
                if isinstance(obj, Decimal):
                    return float(obj)
                raise TypeError(f"Object of type {obj.__class__.__name__} is not JSON serializable")
            
            data = []
            for row in rows:
                row_dict = {}
                for col, val in zip(columns, row):
                    if isinstance(val, Decimal):
                        row_dict[col] = float(val)
                    else:
                        row_dict[col] = val
                data.append(row_dict)
            
            # è¿”å›æ ¼å¼åŒ–çš„ç»“æœ
            return json.dumps(data, ensure_ascii=False, indent=2, default=default_serializer)
            
    except Exception as e:
        return f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}"

# æ–°å¢å›¾è¡¨ç”Ÿæˆå·¥å…·
@tool(
    name="generate_chart",
    description="æ ¹æ®æ•°æ®ç”Ÿæˆå›¾è¡¨",
    show_result=True,
    tool_hooks=[logger_hook]
)
def generate_chart(chart_type: str, data: str, x_column: str, y_column: str, title: str) -> str:
    """
    ç”Ÿæˆå›¾è¡¨å¹¶ä¿å­˜ä¸ºHTMLæ–‡ä»¶
    
    å‚æ•°:
    chart_type: å›¾è¡¨ç±»å‹ ("bar", "line", "pie")
    data: JSONæ ¼å¼çš„æ•°æ®
    x_column: Xè½´ä½¿ç”¨çš„åˆ—å
    y_column: Yè½´ä½¿ç”¨çš„åˆ—å
    title: å›¾è¡¨æ ‡é¢˜
    
    è¿”å›:
    å›¾è¡¨æ–‡ä»¶çš„è·¯å¾„
    """
    import pandas as pd
    import plotly.express as px
    import plotly.io as pio
    import uuid
    
    # è®¾ç½®é»˜è®¤ä¸»é¢˜ä¸ºplotly_whiteï¼Œç¡®ä¿å›¾è¡¨æœ‰æ˜äº®çš„èƒŒæ™¯
    pio.templates.default = "plotly_white"
    
    # è§£ææ•°æ®
    data_list = json.loads(data)
    df = pd.DataFrame(data_list)
    
    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    chart_id = str(uuid.uuid4())
    chart_path = f"/tmp/chart_{chart_id}.html"
    
    # å®šä¹‰é©¬å¡é¾™è‰²ç³»è°ƒè‰²æ¿ï¼Œä»é‡è‰²åˆ°è½»è‰²
    macaron_colors = [
        '#FF9AA2',  # çŠç‘šç²‰
        '#FFB7B2',  # æµ…çŠç‘š
        '#FFDAC1',  # æ·¡æ¡ƒè‰²
        '#E2F0CB',  # è–„è·ç»¿
        '#B5EAD7',  # æ·¡é’ç»¿
        '#C7CEEA',  # æ·¡ç´«
        '#F8B195',  # æ©™ç²‰
        '#F67280',  # ç«ç‘°ç²‰
        '#C06C84',  # ç´«çº¢
        '#6C5B7B',  # æ·¡ç´«ç°
        '#F16D7A',  # é©¬å¡é¾™è‰è“å¥¶éœœ
        '#E27386',  # é©¬å¡é¾™ç«ç‘°
        '#F55066',  # é©¬å¡é¾™ç«ç‘°ç²‰çº¢
        '#EF5464',  # é©¬å¡é¾™åŸºå°”Anperiaru
        '#AE716E',  # å¤§å·§å…‹åŠ›æä»é¥¼
        '#CB8E85',  # å·§å…‹åŠ›é©¬å¡é¾™
        '#CF8878',  # æä»é¥¼ï¼Œæœä»ç³–ï¼Œå·§å…‹åŠ›
        '#C86F67',  # è¦†ç›†å­é©¬å¡é¾™
        '#F1CCB8',  # ç›ç„¦ç³–æä»é¥¼
        '#F2DEBD',  # æä»é¥¼é¦™è‰å¥¶æ²¹
        '#B7D28D',  # é©¬å¡é¾™æŠ¹èŒ¶å¥¶éœœ
        '#DCFF93',  # å¼€å¿ƒæœæä»æä»é¥¼
        '#FF9B6A',  # ç‰›å¥¶å’–å•¡é©¬å¡é¾™
        '#F1B8E4',  # é©¬å¡é¾™ç²‰
        '#D9B8F1',  # æä»é¥¼ç´«
        '#F1F1B8',  # æä»é¥¼é»„è‰²
        '#B8F1ED',  # æä»é¥¼æµ·æ´‹è“
        '#B8F1CC',  # æä»é¥¼ç»¿è‰²
        '#E7DAC9',  # é©¬å¡é¾™æ«æ­¦
        '#E1622F',  # æä»é¥¼è”“è—¤
        '#F3D64E',  # æä»é¥¼ï¼ŒæŸšå­
        '#FD7D36',  # é©¬å¡é¾™ç«ç‘°æœ
        '#FE9778',  # é©¬å¡é¾™è¦†ç›†å­ä¹³é…ªè›‹ç³•
        '#C38E9E',  # é©¬å¡é¾™æ«è–°è¡£è‰
        '#F28860',  # å·§å…‹åŠ›é©¬å¡é¾™é©¬é¾™
        '#DE772C',  # é©¬å¡é¾™è¾¾ç±³å®‰
        '#E96A25',  # é©¬å¡é¾™æœä»å·§å…‹åŠ›
        '#CA7497',  # é©¬å¡é¾™é»‘é†‹æ —
        '#E29E4B',  # é©¬å¡é¾™æ¿€æƒ…å·§å…‹åŠ›
        '#EDBF2B',  # é©¬å¡é¾™Powaru
        '#FECF45',  # é©¬å¡é¾™èŠ’æœæ¿€æƒ…
        '#F9B747',  # é©¬å¡é¾™æŸšå­ï¼Œè¦†ç›†å­
        '#C17E61',  # é©¬å¡é¾™è®©JAæ–—
        '#ED9678',  # æä»é¥¼ç‰›è½§ç³–
        '#FFE543',  # é©¬å¡é¾™å¯å¯å‡¤æ¢¨
        '#E37C5B',  # é©¬å¡é¾™ä¼¯çˆµèŒ¶
        '#FF8240',  # é©¬å¡é¾™å·§å…‹åŠ›æ©™
        '#AA5B71',  # é©¬å¡é¾™å·§å…‹åŠ›æ¨±æ¡ƒè‰²
        '#F0B631',  # å·§å…‹åŠ›é©¬å¡é¾™Bananu
        '#CF8888'   # é©¬å¡é¾™Kurakkure
    ]
    
    # æ ¹æ®ç±»å‹ç”Ÿæˆå›¾è¡¨ï¼Œä½¿ç”¨é©¬å¡é¾™è‰²ç³»
    if chart_type == "bar":
        # å¯¹æ•°æ®æŒ‰yå€¼æ’åºï¼Œå®ç°ä»é«˜åˆ°ä½çš„é¢œè‰²æ¸å˜æ•ˆæœ
        df_sorted = df.sort_values(by=y_column, ascending=False)
        # ä½¿ç”¨é©¬å¡é¾™è‰²ç³»çš„è¿ç»­è‰²é˜¶
        fig = px.bar(df_sorted, x=x_column, y=y_column, title=title, 
                     color=y_column, color_continuous_scale=macaron_colors)
    elif chart_type == "line":
        # çº¿å›¾ä½¿ç”¨é©¬å¡é¾™è‰²ç³»
        fig = px.line(df, x=x_column, y=y_column, title=title,
                      color_discrete_sequence=macaron_colors[:len(df)])
    elif chart_type == "pie":
        # é¥¼å›¾ä½¿ç”¨é©¬å¡é¾™è‰²ç³»
        fig = px.pie(df, values=y_column, names=x_column, title=title, 
                     color_discrete_sequence=macaron_colors[:len(df)])
    else:
        # é»˜è®¤ä½¿ç”¨æŸ±çŠ¶å›¾
        df_sorted = df.sort_values(by=y_column, ascending=False)
        fig = px.bar(df_sorted, x=x_column, y=y_column, title=title,
                     color=y_column, color_continuous_scale=macaron_colors)
    
    # æ›´æ–°å›¾è¡¨å¸ƒå±€ï¼Œç¡®ä¿ä½¿ç”¨æ˜äº®ä¸»é¢˜
    fig.update_layout(
        template="plotly_white",
        font=dict(size=12),
        title_font=dict(size=16)
    )
    
    # ä¿å­˜å›¾è¡¨
    fig.write_html(chart_path)
    return chart_path

# æ–°å¢å·¥å…·ï¼šè¯»å–ç»„ç»‡ç»“æ„ä¿¡æ¯
@tool(
    name="get_organization_structure",
    description="è·å–è”æƒ³å…¬å¸çš„ç»„ç»‡ç»“æ„ä¿¡æ¯",
    show_result=True,
    tool_hooks=[logger_hook]
)
def get_organization_structure() -> str:
    """è·å–è”æƒ³å…¬å¸çš„ç»„ç»‡ç»“æ„ä¿¡æ¯"""
    org_file_path = "/home/Finance_v2/kpi_matrix/organization_relationship.json"
    
    if not os.path.exists(org_file_path):
        return "ç»„ç»‡ç»“æ„æ–‡ä»¶æœªæ‰¾åˆ°"
    
    try:
        with open(org_file_path, 'r', encoding='utf-8') as f:
            org_data = json.load(f)
        
        # è§£æç»„ç»‡ç»“æ„ä¿¡æ¯
        lenovo_data = org_data.get("Lenovo", {})
        
        def extract_entities(data, entities=None):
            """é€’å½’æå–æ‰€æœ‰å®ä½“"""
            if entities is None:
                entities = set()
            
            if isinstance(data, dict):
                for key, value in data.items():
                    entities.add(key)
                    extract_entities(value, entities)
            elif isinstance(data, list):
                for item in data:
                    entities.add(item)
            
            return entities
        
        # æå–æ‰€æœ‰ç»„ç»‡å®ä½“
        all_entities = extract_entities(lenovo_data)
        
        # æ„å»ºç»„ç»‡ç»“æ„ä¿¡æ¯æ‘˜è¦
        org_summary = {
            "æ€»å®ä½“æ•°": len(all_entities),
            "ç»„ç»‡å®ä½“": list(all_entities)
        }
        
        return json.dumps(org_summary, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return f"è¯»å–ç»„ç»‡ç»“æ„ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}"

# æ–°å¢å·¥å…·ï¼šè¯»å–è´¢åŠ¡å…¬å¼å’Œå­—å…¸ä¿¡æ¯
@tool(
    name="get_financial_formulas_and_dictionaries",
    description="è·å–è´¢åŠ¡å…¬å¼å’Œå­—å…¸ä¿¡æ¯ï¼ŒåŒ…æ‹¬æŒ‡æ ‡è®¡ç®—æ–¹æ³•å’Œæœ¯è¯­å®šä¹‰",
    show_result=True,
    tool_hooks=[logger_hook]
)
def get_financial_formulas_and_dictionaries() -> str:
    """è·å–è´¢åŠ¡å…¬å¼å’Œå­—å…¸ä¿¡æ¯"""
    formulas_dict_file_path = "/home/Finance_v2/kpi_matrix/Financial_formulas_and_dictionaries.json"
    
    if not os.path.exists(formulas_dict_file_path):
        return "è´¢åŠ¡å…¬å¼å’Œå­—å…¸æ–‡ä»¶æœªæ‰¾åˆ°"
    
    try:
        with open(formulas_dict_file_path, 'r', encoding='utf-8') as f:
            formulas_dict_data = json.load(f)
        
        return json.dumps(formulas_dict_data, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return f"è¯»å–è´¢åŠ¡å…¬å¼å’Œå­—å…¸ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}"

def initialize_app():
    st.title("ğŸ” Chat to Financial Data")
    
    if "msgs" not in st.session_state:
        st.session_state["msgs"] = []
        
    if "current_kpi" not in st.session_state:
        st.session_state["current_kpi"] = None
        
    if "kpi_parameters" not in st.session_state:
        st.session_state["kpi_parameters"] = {}
        
    return True

def load_all_kpi_info():
    """åŠ è½½æ‰€æœ‰KPIä¿¡æ¯ç”¨äºæ„å»ºæ›´è¯¦ç»†çš„æç¤ºè¯"""
    kpi_info_list = []
    kpi_directory = "/home/Finance_v2/kpi_matrix/kpis"
    
    for i in range(1, 11):
        kpi_file_path = os.path.join(kpi_directory, f"{i}.json")
        if os.path.exists(kpi_file_path):
            with open(kpi_file_path, 'r', encoding='utf-8') as f:
                kpi_data = json.load(f)
                kpi_info = {
                    "id": str(i),
                    "name": kpi_data["kpi_desc"]["name"],
                    "description": kpi_data["kpi_desc"]["description"],
                    "measures": kpi_data["measures"],
                    "dimensions": kpi_data["dimensions"],
                    "sql_query": kpi_data["sql_query"]["query"]
                }
                kpi_info_list.append(kpi_info)
    
    return kpi_info_list

def format_kpi_info_for_prompt(kpi_info_list):
    """å°†KPIä¿¡æ¯æ ¼å¼åŒ–ä¸ºæç¤ºè¯"""
    formatted_kpis = []
    for kpi in kpi_info_list:
        kpi_text = f"""
KPI ID: {kpi['id']}
åç§°: {kpi['name']}
æè¿°: {kpi['description']}
åº¦é‡æŒ‡æ ‡: {', '.join(kpi['measures'])}
ç»´åº¦: {', '.join(kpi['dimensions'])}
ç¤ºä¾‹SQLæŸ¥è¯¢: {kpi['sql_query']}"""
        formatted_kpis.append(kpi_text)
    
    return "\n\n".join(formatted_kpis)
# æ›¿æ¢ setup_agent() å‡½æ•°ä¸­çš„æ¨¡å‹åˆå§‹åŒ–éƒ¨åˆ†
# æ›¿æ¢ setup_agent() å‡½æ•°ä¸­çš„æ¨¡å‹åˆå§‹åŒ–éƒ¨åˆ†
def setup_agent():
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # åŠ è½½æ‰€æœ‰KPIä¿¡æ¯
    kpi_info_list = load_all_kpi_info()
    formatted_kpi_info = format_kpi_info_for_prompt(kpi_info_list)
    
    # åŠ è½½è´¢åŠ¡å…¬å¼å’Œå­—å…¸ä¿¡æ¯
    formulas_dict_file_path = "/home/Finance_v2/kpi_matrix/Financial_formulas_and_dictionaries.json"
    try:
        with open(formulas_dict_file_path, 'r', encoding='utf-8') as f:
            financial_formulas_dict = json.load(f)
        formatted_formulas_dict = json.dumps(financial_formulas_dict, ensure_ascii=False, indent=2)
    except Exception as e:
        formatted_formulas_dict = f"æ— æ³•åŠ è½½è´¢åŠ¡å…¬å¼å’Œå­—å…¸: {str(e)}"
    
    # åˆ›å»ºè‡ªå®šä¹‰çš„è”æƒ³APIæ¨¡å‹ç±»
    from agno.models.base import Model
    from agno.models.message import Message
    from agno.models.response import ModelResponse
    import requests
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    
    class LenovoAPIModel(Model):
        def __init__(self):
            super().__init__(id="gpt-4o-mini")
            self.api_key = "VBOyFcVkgJuGwhTROgbB1atm7QlVhI1z"
            self.token_url = "https://apihub-us.lenovo.com/token"
            self.api_url = "https://apihub-us.lenovo.com/prod/v1/services/aiverse-ukm/ics-apps/projects/115/ukm/aiverse/endpoint/v1/chat/completions"
            self.access_token = None
            self._get_token()
        
        def _get_token(self):
            """è·å–è”æƒ³APIè®¿é—®ä»¤ç‰Œ"""
            token_payload = {
                'username': 'api_akm_aiesa',
                'password': 'YB=&f%6$C-'
            }
            
            token_headers = {
                "X-API-KEY": self.api_key,
                "Content-Type": "application/x-www-form-urlencoded",
                "User-Agent": "Harbor/0.0.1 (Python)"
            }
            
            try:
                response = requests.post(
                    self.token_url, 
                    headers=token_headers, 
                    data=token_payload, 
                    verify=False, 
                    timeout=30
                )
                
                if response.status_code == 200:
                    token_data = response.json()
                    self.access_token = token_data.get('access_token')
                else:
                    raise Exception(f"Failed to get token: {response.status_code} - {response.text}")
                    
            except Exception as e:
                raise Exception(f"Error getting token: {str(e)}")
        
        def _parse_provider_response(self, response: dict) -> ModelResponse:
            """è§£ææä¾›å•†å“åº”"""
            if 'choices' in response and len(response['choices']) > 0:
                content = response['choices'][0]['message']['content']
                return ModelResponse(content=content)
            else:
                raise Exception("No response content from API")
        
        def _parse_provider_response_delta(self, response: dict) -> ModelResponse:
            """è§£ææµå¼å“åº”å¢é‡"""
            if 'choices' in response and len(response['choices']) > 0:
                delta = response['choices'][0].get('delta', {})
                content = delta.get('content', '')
                return ModelResponse(content=content)
            else:
                return ModelResponse(content='')
        
        def invoke(self, messages, **kwargs):
            """è°ƒç”¨è”æƒ³API"""
            if not self.access_token:
                self._get_token()
                
            api_payload = {
                "model": "gpt-4o-mini",
                "stream": False,
                "messages": [{"role": m.role, "content": m.content} for m in messages],
                "max_tokens": 1024,
                "temperature": 0.7,
                "top_p": 0.9
            }
            
            api_headers = {
                "Authorization": f"Bearer {self.access_token}",
                "X-API-KEY": self.api_key,
                "Content-Type": "application/json",
                "User-Agent": "Harbor/0.0.1 (Python)"
            }
            
            try:
                response = requests.post(
                    self.api_url, 
                    headers=api_headers, 
                    json=api_payload, 
                    verify=False, 
                    timeout=60
                )
                
                if response.status_code == 200:
                    api_data = response.json()
                    return self._parse_provider_response(api_data)
                else:
                    # å¦‚æœæ˜¯è®¤è¯é”™è¯¯ï¼Œå°è¯•é‡æ–°è·å–token
                    if response.status_code == 401:
                        self._get_token()
                        # é‡æ–°å°è¯•ä¸€æ¬¡è¯·æ±‚
                        api_headers["Authorization"] = f"Bearer {self.access_token}"
                        response = requests.post(
                            self.api_url, 
                            headers=api_headers, 
                            json=api_payload, 
                            verify=False, 
                            timeout=60
                        )
                        if response.status_code == 200:
                            api_data = response.json()
                            return self._parse_provider_response(api_data)
                    
                    raise Exception(f"API call failed: {response.status_code} - {response.text}")
                    
            except Exception as e:
                raise Exception(f"Error calling Lenovo API: {str(e)}")
        
        async def ainvoke(self, messages, **kwargs):
            """å¼‚æ­¥è°ƒç”¨è”æƒ³API"""
            # ç®€å•å®ç°åŒæ­¥è°ƒç”¨çš„å¼‚æ­¥ç‰ˆæœ¬
            return self.invoke(messages, **kwargs)
        
        def invoke_stream(self, messages, **kwargs):
            """æµå¼è°ƒç”¨è”æƒ³API"""
            if not self.access_token:
                self._get_token()
                
            api_payload = {
                "model": "gpt-4o-mini",
                "stream": True,  # å¯ç”¨æµå¼ä¼ è¾“
                "messages": [{"role": m.role, "content": m.content} for m in messages],
                "max_tokens": 1024,
                "temperature": 0.7,
                "top_p": 0.9
            }
            
            api_headers = {
                "Authorization": f"Bearer {self.access_token}",
                "X-API-KEY": self.api_key,
                "Content-Type": "application/json",
                "User-Agent": "Harbor/0.0.1 (Python)"
            }
            
            try:
                response = requests.post(
                    self.api_url, 
                    headers=api_headers, 
                    json=api_payload, 
                    verify=False, 
                    timeout=60,
                    stream=True
                )
                
                if response.status_code == 200:
                    # å¤„ç†æµå¼å“åº”
                    for line in response.iter_lines():
                        if line:
                            decoded_line = line.decode('utf-8')
                            if decoded_line.startswith('data: '):
                                data = decoded_line[6:]  # ç§»é™¤ 'data: ' å‰ç¼€
                                if data != '[DONE]':
                                    try:
                                        json_data = json.loads(data)
                                        yield self._parse_provider_response_delta(json_data)
                                    except json.JSONDecodeError:
                                        continue
                else:
                    # å¦‚æœæ˜¯è®¤è¯é”™è¯¯ï¼Œå°è¯•é‡æ–°è·å–token
                    if response.status_code == 401:
                        self._get_token()
                        # é‡æ–°å°è¯•ä¸€æ¬¡è¯·æ±‚
                        api_headers["Authorization"] = f"Bearer {self.access_token}"
                        response = requests.post(
                            self.api_url, 
                            headers=api_headers, 
                            json=api_payload, 
                            verify=False, 
                            timeout=60,
                            stream=True
                        )
                        if response.status_code == 200:
                            for line in response.iter_lines():
                                if line:
                                    decoded_line = line.decode('utf-8')
                                    if decoded_line.startswith('data: '):
                                        data = decoded_line[6:]
                                        if data != '[DONE]':
                                            try:
                                                json_data = json.loads(data)
                                                yield self._parse_provider_response_delta(json_data)
                                            except json.JSONDecodeError:
                                                continue
                    
                    raise Exception(f"API call failed: {response.status_code} - {response.text}")
                    
            except Exception as e:
                raise Exception(f"Error calling Lenovo API: {str(e)}")
        
        async def ainvoke_stream(self, messages, **kwargs):
            """å¼‚æ­¥æµå¼è°ƒç”¨è”æƒ³API"""
            # ç®€å•å®ç°åŒæ­¥æµå¼è°ƒç”¨çš„å¼‚æ­¥ç‰ˆæœ¬
            for response in self.invoke_stream(messages, **kwargs):
                yield response
    
    # ä½¿ç”¨è‡ªå®šä¹‰çš„è”æƒ³APIæ¨¡å‹
    lenovo_model = LenovoAPIModel()
    
    agent = Agent(
        model=lenovo_model,
        markdown=True,
        tools=[
            ReasoningTools(add_instructions=True),
            identify_kpi,
            get_kpi_info,
            get_organization_structure,
            get_financial_formulas_and_dictionaries,
            query_mysql,
            generate_chart,
            TavilyTools(api_key="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"),
        ],

        instructions=dedent(f"""
                            
            You are Lenovo SSG Financail KPI analysis assistant,your name is Superman ,capable of helping users query and analyze various Financial metrics.
            
            Current time: {current_time},
            Time peroid: in Lenovo ,we are actually in FY 25/26
            
            Your capabilities include:
            1. Judging whether user questions are casual chat or KPI queries
            2. Identifying the specific KPI type the user wants to query,and pay attention to not take the KPI example as a query directly
            3. Obtaining detailed KPI information and required parameters
            4. Checking parameter completeness, and guiding users to supplement if parameters are missing
            5. Executing database queries and returning detailed, clear and intuitive results
            6. Generating charts from the data to visualize KPIs
            7. Providing organizational structure information when requested
            8. Providing financial formulas and dictionaries for better understanding of financial metrics
            9. If users want to chat casually, please accompany them in conversation
            
            The following is the available KPI information:
            {formatted_kpi_info}
            
            Workflow:
            1. First judge the user question type (casual chat/KPI query)
            2. If it's a KPI query, identify the specific KPI type
            3. Obtain the DSL information {formatted_kpi_info} for that KPI
            4. Check if additional parameters are needed
            5. If needed, guide the user to supplement parameters
            6. Execute the query and display detailed results in an intuitive and clear manner, such as tables, etc.
            7. If appropriate, generate charts to visualize the data
            8. If users ask about organizational structure, use the get_organization_structure tool to provide information
            9. If users ask about financial formulas or terms, use the get_financial_formulas_and_dictionaries tool to provide explanations
            10. If users want to chat casually, please accompany them in conversation
            11. Share your final sql query to the user.
            
            Notes:
            - Strictly execute queries according to the KPI-defined SQL query structure
            - When users inquire about specific KPIs, please refer to the corresponding SQL query structure and fields
            - If the user's question does not match any KPI, please engage in casual chat or request clarification
            - Ensure the language of the output answers is the same language used by the user
            - Showing your thinking process
            - When generating charts, select the most appropriate chart type for the data:
              * Bar charts for comparisons
              * Line charts for trends over time
              * Pie charts for proportions
            - When users ask about organizational structure, use the get_organization_structure tool to provide comprehensive information
            - When explaining financial metrics, use the get_financial_formulas_and_dictionaries tool to provide accurate definitions and calculation methods
            - When explaining financial terms, refer to the Financial Formulas and Dictionaries section above for accurate definitions
        """),
        reasoning=False,
    )
    return agent
def process_assistant_response(agent, messages):
    # åˆ›å»ºå›ç­”å ä½ç¬¦
    message_placeholder = st.empty()
    
    full_response = ""
    
    run_response = agent.run(
        messages, 
        stream=True
    )
    
    for chunk in run_response:
        # å¤„ç†å›ç­”å†…å®¹
        if chunk.content:
            full_response += chunk.content
            message_placeholder.markdown(full_response + "â–Œ")
    
    # æ›´æ–°æœ€ç»ˆå†…å®¹ï¼ˆå»æ‰å…‰æ ‡ï¼‰
    message_placeholder.markdown(full_response)
    
    return full_response

def main():
    initialize_app()
    agent = setup_agent()
    
    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for msg in st.session_state["msgs"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            
            # å¦‚æœæ¶ˆæ¯ä¸­åŒ…å«å›¾è¡¨è·¯å¾„ï¼Œåˆ™æ˜¾ç¤ºå›¾è¡¨
            import re
            chart_paths = re.findall(r"/tmp/chart_[a-f0-9-]+\.html", msg["content"])
            # å»é‡ä»¥é¿å…é‡å¤æ˜¾ç¤º
            chart_paths = list(set(chart_paths))
            for chart_path in chart_paths:
                if os.path.exists(chart_path):
                    with open(chart_path, "r") as f:
                        chart_html = f.read()
                        st.components.v1.html(chart_html, height=500)

    if prompt := st.chat_input("talk to me"):
        st.session_state["msgs"].append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            full_response = process_assistant_response(agent, st.session_state["msgs"])
            st.session_state["msgs"].append({"role": "assistant", "content": full_response})
            
            # å¦‚æœå“åº”ä¸­åŒ…å«å›¾è¡¨è·¯å¾„ï¼Œåˆ™æ˜¾ç¤ºå›¾è¡¨
            import re
            chart_paths = re.findall(r"/tmp/chart_[a-f0-9-]+\.html", full_response)
            # å»é‡ä»¥é¿å…é‡å¤æ˜¾ç¤º
            chart_paths = list(set(chart_paths))
            for chart_path in chart_paths:
                if os.path.exists(chart_path):
                    with open(chart_path, "r") as f:
                        chart_html = f.read()
                        st.components.v1.html(chart_html, height=500)

if __name__ == "__main__":
    main()